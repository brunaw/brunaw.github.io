<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Finding errors in R</title>
  <meta name="author" content="" />

  
  <meta name="keywords" content="RStats, Statistics, Diversity">	
  

  
  <meta name="description" content="Bruna&#39;s Homepage">	
  

  <meta name="generator" content="Hugo 0.49" />

  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="https://brunaw.com/css/animate.css" rel="stylesheet">

  
  
    <link href="https://brunaw.com/css/style.pink.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="https://brunaw.com/css/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="https://brunaw.com/img/beach.png" type="image/x-icon" />
  <link rel="apple-touch-icon" href="https://brunaw.com/img/apple-touch-icon.png" />
  

  <link href="https://brunaw.com/css/owl.carousel.css" rel="stylesheet">
  <link href="https://brunaw.com/css/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="https://brunaw.com/index.xml" type="application/rss+xml" title="Bruna Wundervald">

  
  <meta property="og:title" content="Finding errors in R" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/blog/2019/10/06/2019-10-06-finding-errors//" />
  <meta property="og:image" content="img/beach2.png" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="https://brunaw.com/">
                    <img src="https://brunaw.com/img/beach2.png" alt="Finding errors in R logo" class="hidden-xs hidden-sm">
                    <img src="https://brunaw.com/img/beach2.png" alt="Finding errors in R logo" class="visible-xs visible-sm">
                    <span class="sr-only">Finding errors in R - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  <li class="dropdown">
                    
                    <a href="/">Home</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Research <span class="caret"></span></a>
                    <ul class="dropdown-menu">
                      
                        <li><a href="/projects/">Projects</a></li>
                      
                        <li><a href="/publications/">Publications</a></li>
                      
                        <li><a href="/material/">Material</a></li>
                      
                        <li><a href="/software/">Software</a></li>
                      
                        <li><a href="/recommendations/">Recommendations</a></li>
                      
                    </ul>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/blog/">Posts</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/docs/curriculum_vitae.pdf">Curriculum</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/contact">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Finding errors in R</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        <p class="text-muted text-uppercase mb-small text-right">By <a href="#">[Bruna Wundervald]</a> | October 6, 2019</p>

                        <div id="post-content">
                          <script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Decision trees ensembles are a very popular
type of machine learning algorithm, which is mostly due
to their adaptive nature, high prediction power and, in
some sense, interpretability. Random Forests are one
form of such ensembles, and they consist of growing many
trees in re-samples of the data, and averaging their results
at end, creating a bagged ensemble described <span class="citation">[@Breiman1996]</span> by</p>
<p><span class="math display">\[\begin{equation} 
\hat f(\mathbf{x}) = \sum_{n = 1}^{N_{tree}} \frac{1}{N_{tree}} \hat f_n(\mathbf{x}),
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\hat f_n\)</span> corresponds to the <span class="math inline">\(n\)</span>-th tree. However,
even though we can name many very good qualities of the
Random Forests, we also know that they don’t do
feature selection very well. However, Random Forests usually use all
or most of the features that are feed to them, and they
struggle a lot to detect highly correlated features
<span class="citation">[@phdthesisRF]</span>, that ideally
shouldn’t be used in an algorithm more than once. In a
situation where predictions are hard or expensive to
obtain (e.g. genetic related data such as SNPs, peptides or proteins), this becomes a relevant issue that needs to
be addressed if we realistically want to use RFs for such prediction tasks.</p>
<p>In this post, I will give a general overview of feature
selection in Random Forests using gain penalization. The
<code>R</code> code is provided along with the explanation, and I’ll
often be referring to my own paper on the subject <span class="citation">[@wundervald2020generalizing]</span>. A few auxiliary functions are used
throughout the code, and they can be found <a href="https://github.com/brunaw/reg-rf-demo/blob/master/code">here</a>.</p>
</div>
<div id="what-is-gain-penalization" class="section level2">
<h2>What is Gain Penalization?</h2>
<p>The idea of doing feature selection via gain penalization
was first introduced in <span class="citation">[@rrf_paper]</span>, and it is basically
a gain weighting method, done during the greedy procedure
step of a tree estimation. In other words, when determining
the next child node to be added to a decision tree,
the gain (or the error reduction) of each feature
is multiplied by a penalization parameter. With this, a new
split will only be made if, after the penalization,
the gain of adding this node is still higher than having
no new child node in the tree. This new penalized gain
is written as</p>
<p><span class="math display">\[\begin{equation}
\text{Gain}_{R}(\mathbf{X}_{i}, t) = 
\begin{cases}
\lambda \Delta(i, t), \thinspace  i \notin \mathbb{U} \text{ and} \\
\Delta(i, t), \thinspace  i \in \mathbb{U}, 
\end{cases}
\label{eq:grrf}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathbb{U}\)</span> is the set of indices of the features previously
used in the tree, <span class="math inline">\(\mathbf{X}_{i}\)</span> is the candidate feature,
<span class="math inline">\(t\)</span> is the candidate splitting point and <span class="math inline">\(\lambda \in (0, 1]\)</span>.</p>
<p>In our paper <span class="citation">[@wundervald2020generalizing]</span>, we proposed
a generalization to the way the penalization coefficients
are calculated, such that we can have full control over it.
Our <span class="math inline">\(\lambda_i\)</span> is written as</p>
<p><span class="math display">\[\begin{equation}
\lambda_i = (1 - \gamma) \lambda_0 + \gamma g(\mathbf{x}_i),
\label{eq:generalization}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\lambda_0 \in [0, 1)\)</span> is interpreted as the
baseline regularization, <span class="math inline">\(g(\mathbf{x}_i)\)</span>
is a function of the <span class="math inline">\(i\)</span>-th feature,
and <span class="math inline">\(\gamma \in [0, 1)\)</span> is their mixture parameter,
with <span class="math inline">\(\lambda_i \in [0, 1)\)</span>. The idea behind this composition is creating a local-global form of penalization,
since the equation mixes how much all features are jointly
(globally) penalized and how much it is due
to a local <span class="math inline">\(g(\mathbf{x}_i)\)</span>, which is manually defined.
This <span class="math inline">\(g(\mathbf{x}_i)\)</span>, by its turn,
should represent relevant information about the
features, based on some characteristic of interest
(correlation to the target, for example).
This formulation also has inspiration on the
use of priors made in Bayesian methods, since we
introduce “prior knowledge” regarding the importance
of each feature into the model (likewise, the data will tell us how strong our assumptions about the penalization are, since even if we try to penalize a truly important feature, its gain will be high enough to overcome the penalization and the feature will get selected by the algorithm).</p>
<p>In this blog post, I’ll use two different types of <span class="math inline">\(g(\mathbf{x}_i)\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>The Mutual Information between each feature and the
target variable <span class="math inline">\(y\)</span> (normalized to be between 0 and 1)</p></li>
<li><p>The variable importance values obtained from a previously
run standard Random Forest, which is what I call a
<em>Boosted</em> <span class="math inline">\(g(\mathbf{x}_i)\)</span><br />
(also normalized to be between 0 and 1)</p></li>
</ol>
<p>For more details on those functions and other options, please
see the paper <span class="citation">[@wundervald2020generalizing]</span>.</p>
</div>
<div id="the-full-feature-selection-procedure" class="section level2">
<h2>The full feature selection procedure</h2>
<p>In general, the penalized random forest model is not the one that will
be used for the final predictions. Instead, I prefer to use the
method described before as a tool to first select the best
features possible, and then have a
final random forest that uses such features. This full feature selection
procedure happens in 3 main steps:</p>
<ol style="list-style-type: decimal">
<li>We run a bunch of penalized random forests models
with different hyperparameters and record their accuracies and final set of features</li>
<li>For each training dataset, select the top-n (for this post we use n = 3) fitted models in terms of the accuracies, and run a “new” random
forest for each of the feature sets used by them. This is done using all
of the training sets so we can evaluate how these features perform in slightly different scenarios</li>
<li>Finally, get the top-m set of models (here m = 30) from these
new ones, check which features were the most used between them
and run a final random forest model with this feature set. In this
post I select only the 15 most used features from the top 30 models,
but both numbers can be changed depending on the situation</li>
</ol>
<p>All this is to make sure that the features used in the final model are, indeed, very good. This might sound a bit exhaustive but to me it pays
off knowing that out of a few thousand variables, I’ll manage to select
only a few and still have a powerful and generalizable model.</p>
<div id="things-to-have-in-mind-when-running-the-penalized-rf" class="section level3">
<h3>Things to have in mind when running the penalized RF</h3>
<ul>
<li><p>You can add an “extra penalization” when the new variable is to
be picked at a deep node in a tree (for details please see the paper)</p></li>
<li><p>The <code>mtry</code> hyperparameter requires attention (and even proper tuning),
since it is known that to affect the prediction power of random forests and, is our case, the penalized random forests</p></li>
<li><p>Ideally, the <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(\lambda_0\)</span> and <code>mtry</code> hyperparameters should
be tuned, or set based on the experience of the person running the
algorithms, but for the time being we’ll be using a few predefined
values (kind of like grid search)</p></li>
</ul>
</div>
</div>
<div id="implementation" class="section level2">
<h2>Implementation</h2>
<p>Let us consider the <code>gravier</code> dataset <span class="citation">[@gravier2010prognostic]</span>, for which
the goal is to predict whether 168 breast cancer patients had a diagnosis
labelled “poor” (~66%) or “good” (~33%), based on a a set of 2905
predictors. In this first part of the code, we’ll just load the data and
create our 5-fold cross validation object, which will be used to
create 5 different train and test sets. As of usual, there will
be lots of <code>tidyverse</code> and <code>tidymodels</code> functions throughout my
code:</p>
<pre class="r"><code>library(tidyverse)
library(tidymodels)
library(infotheo) # For the mutual information function
set.seed(2021)

# Loading data and creating a 5-fold CV object
data(&#39;gravier&#39;, package = &#39;datamicroarray&#39;)

gravier &lt;- data.frame(class = gravier$y, gravier$x)
folds &lt;- rsample::vfold_cv(gravier, v = 5) %&gt;% 
  dplyr::mutate(train =  map(splits, training),
                test  = map(splits, testing))</code></pre>
<p>With this done, we can start the actual modelling steps of the code.
I will be using a few of auxiliary functions, which are given <a href="https://github.com/brunaw/reg-rf-demo/blob/master/code"><strong>here</strong></a>,
but the two
following functions are explicitly shown in this post because they’re
very important. The <code>modelling()</code> function will be used
to run the random forests algorithms, and it’s written in a way that
I can change the <code>mtry</code> hyperparameter, the penalization
coefficients. At this point we’ll be
feeding all the 2905 features, and letting the gain penalization
perform the feature selection for us. The second function
shown below is <code>penalization()</code>, which implements the
calculation of two different types of penalization: one
that takes <span class="math inline">\(g(\mathbf{x}_i)\)</span> to be the normalized
mutual information between
the target and each feature, and one that I call a “Boosted”
<span class="math inline">\(g(\mathbf{x}_i)\)</span>, because it depends on the normalized
importance values of a previously calculated random forest
(for more details, see <span class="citation">@wundervald2020generalizing</span>).</p>
<pre class="r"><code># A function that run the penalized random forests models 
modelling &lt;- function(train, reg_factor = 1, mtry = 1){
  rf_mod &lt;- 
    rand_forest(trees = 500, mtry = (mtry * ncol(train)) - 1) %&gt;% 
    set_engine(&quot;ranger&quot;, importance = &quot;impurity&quot;, 
               regularization.factor = reg_factor) %&gt;% 
    set_mode(&quot;classification&quot;) %&gt;% 
    parsnip::fit(class ~ ., data = train)
  return(rf_mod)
}
# A function that receives the mixing parameters
# and calculates lambda_i with the chose g(x_i)
penalization &lt;- function(gamma, lambda_0, data = NULL, imps = NULL, type = &quot;rf&quot;){
  if(type == &quot;rf&quot;){
    # Calculating the normalized importance values 
    imps &lt;- imps/max(imps)
    imp_mixing &lt;- (1 - gamma) * lambda_0 + imps * gamma 
    return(imp_mixing)
  } else if(type == &quot;MI&quot;){
    mi &lt;- function(data, var) mutinformation(c(data$class), data %&gt;% pull(var))
    
    # Calculating the normalized mutual information values
    disc_data  &lt;- infotheo::discretize(data) 
    disc_data$class &lt;- as.factor(data$class)
    names_data &lt;- names(data)[-1]
    mi_vars &lt;- names_data  %&gt;% map_dbl(~{mi(data = disc_data, var = .x) })
    mi_mixing &lt;- (1 - gamma) * lambda_0 + gamma * (mi_vars/max(mi_vars))
    return(mi_mixing)  
  }
}</code></pre>
<p>The code below creates the combinations of all hypeparameter values
used here, for the <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(\lambda_0\)</span> and <code>mtry</code> hyperparameters. After
that, we calculate the two <span class="math inline">\(g(\mathbf{x}_i)\)</span> for each training set, and
their final coefficient penalization values by combining them with <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\lambda_0\)</span> to create the penalization mixture (as described previously), for each of the 5 training sets.</p>
<pre class="r"><code># Setting all parameters ---
mtry &lt;-  tibble(mtry = c(0.20, 0.45, 0.85))  
gamma_f  &lt;-  c(0.3, 0.5, 0.8)
lambda_0_f &lt;- c(0.35, 0.75)

parameters &lt;- mtry %&gt;% tidyr::crossing(lambda_0_f, gamma_f)
# Adds gamma_f and lambda_0_f and run the functions with them ------
folds_imp &lt;- folds %&gt;% 
  dplyr::mutate(
    # Run the standard random forest model for the 5 folds
    model = purrr::map(train, modelling), 
    importances_std = purrr::map(model, ~{.x$fit$variable.importance}))  %&gt;%
  tidyr::expand_grid(parameters) %&gt;% 
  dplyr::mutate(imp_rf = purrr::pmap(
    list(gamma_f, lambda_0_f, train, importances_std), type = &quot;rf&quot;, 
    penalization), 
    imp_mi = purrr::pmap(
      list(gamma_f, lambda_0_f, train, importances_std), type = &quot;MI&quot;, penalization)) </code></pre>
<p>A quick look at :</p>
<pre><code>## # A tibble: 3 x 7
##   id    reg_factor     mtry lambda_0_f gamma_f imp_rf        imp_mi       
##   &lt;chr&gt; &lt;list&gt;        &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;list&gt;        &lt;list&gt;       
## 1 Fold1 &lt;dbl [2,905]&gt;   0.2       0.35     0.3 &lt;dbl [2,905]&gt; &lt;dbl [2,905]&gt;
## 2 Fold1 &lt;dbl [2,905]&gt;   0.2       0.35     0.5 &lt;dbl [2,905]&gt; &lt;dbl [2,905]&gt;
## 3 Fold1 &lt;dbl [2,905]&gt;   0.2       0.35     0.8 &lt;dbl [2,905]&gt; &lt;dbl [2,905]&gt;</code></pre>
<p>The <code>folds_imp</code> object has 90 rows, since it is the combination of
2 <span class="math inline">\(\times\)</span> 3 <span class="math inline">\(\times\)</span> 3 hyperparameter combinations for each of the 5 training sets, and 2 different <span class="math inline">\(g(\mathbf{x}_i)\)</span>. Before running our
penalized models, we take a look at the results for the standard
random forests models (the <code>model</code> column). Here, the <code>accuracy</code> and <code>accuracy_std</code> columns represent
the test accuracy and training accuracy from a non-penalized
RF, which was run before to create the penalization
coefficients, so now we can use it for comparison:</p>
<pre class="r"><code>folds_imp %&gt;% 
  dplyr::group_by(id) %&gt;% 
  dplyr::slice(1) %&gt;% 
  dplyr::ungroup() %&gt;% 
  dplyr::select(id, model, train, test) %&gt;% 
  dplyr::mutate(
    model_importance = purrr::map(model, ~{.x$fit$variable.importance}),
    n_var = purrr::map_dbl(model_importance, n_vars), 
    accuracy_test_std = purrr::map2_dbl(
      .x = model, .y = test, ~{ acc_test(.x, test = .y)}),
    accuracy_std = 1 -purrr::map_dbl(model, ~{ .x$fit$prediction.error})
  ) %&gt;% 
  dplyr::select(id, n_var, accuracy_test_std, accuracy_std) </code></pre>
<table class="table table-condensed table-hover" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:right;">
n_var
</th>
<th style="text-align:right;">
accuracy_test_std
</th>
<th style="text-align:right;">
accuracy_std
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Fold1
</td>
<td style="text-align:right;">
1206
</td>
<td style="text-align:right;">
0.735
</td>
<td style="text-align:right;">
0.8481872
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold2
</td>
<td style="text-align:right;">
1380
</td>
<td style="text-align:right;">
0.765
</td>
<td style="text-align:right;">
0.8235503
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold3
</td>
<td style="text-align:right;">
1379
</td>
<td style="text-align:right;">
0.765
</td>
<td style="text-align:right;">
0.8246055
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold4
</td>
<td style="text-align:right;">
1377
</td>
<td style="text-align:right;">
0.788
</td>
<td style="text-align:right;">
0.8260160
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold5
</td>
<td style="text-align:right;">
1198
</td>
<td style="text-align:right;">
0.667
</td>
<td style="text-align:right;">
0.8548713
</td>
</tr>
</tbody>
</table>
<p>The following code runs all the penalized random forests models and calculates
their metrics.</p>
<pre class="r"><code>run_all_models &lt;-  folds_imp %&gt;%   
  dplyr::select(id, model, train, test,  imp_rf, imp_mi, mtry, lambda_0_f, gamma_f) %&gt;% 
  tidyr::gather(type, importance, -train, -test, -mtry,-id, -model, -lambda_0_f, -gamma_f) %&gt;% 
  dplyr::mutate(fit_penalized_rf = purrr::pmap(list(train, importance, mtry), modelling)) </code></pre>
<p>And finally we extract the metrics we’re interested in, from
each estimated model: the number of features used,
accuracy in the test set, and the accuracy calculated
during training:</p>
<pre class="r"><code>results &lt;- run_all_models %&gt;% 
  dplyr::mutate(
    model_importance = purrr::map(fit_penalized_rf, ~{.x$fit$variable.importance}),
    n_var = purrr::map_dbl(model_importance, n_vars),
    accuracy = 1 - purrr::map_dbl(fit_penalized_rf, ~{ .x$fit$prediction.error}),
    accuracy_test = purrr::map2_dbl(
      .x = fit_penalized_rf, .y = test, ~{ acc_test(.x, .y)})) </code></pre>
<p>A quick look at the <code>results</code> object:</p>
<pre class="r"><code>results %&gt;% 
  dplyr::arrange(id, desc(accuracy_test), desc(accuracy), n_var) %&gt;% 
  dplyr::slice(1:5) </code></pre>
<table class="table table-condensed table-hover" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:right;">
mtry
</th>
<th style="text-align:right;">
lambda_0_f
</th>
<th style="text-align:right;">
gamma_f
</th>
<th style="text-align:left;">
type
</th>
<th style="text-align:right;">
n_var
</th>
<th style="text-align:right;">
accuracy
</th>
<th style="text-align:right;">
accuracy_test
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Fold1
</td>
<td style="text-align:right;">
0.85
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
imp_rf
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.8979667
</td>
<td style="text-align:right;">
0.824
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold1
</td>
<td style="text-align:right;">
0.20
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.3
</td>
<td style="text-align:left;">
imp_rf
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
0.8786310
</td>
<td style="text-align:right;">
0.794
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold1
</td>
<td style="text-align:right;">
0.45
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.8
</td>
<td style="text-align:left;">
imp_rf
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
0.9001406
</td>
<td style="text-align:right;">
0.765
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold1
</td>
<td style="text-align:right;">
0.45
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
0.3
</td>
<td style="text-align:left;">
imp_rf
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0.8998857
</td>
<td style="text-align:right;">
0.765
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold1
</td>
<td style="text-align:right;">
0.45
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
imp_rf
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
0.8995989
</td>
<td style="text-align:right;">
0.765
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-12"></span>
<img src="/blog/2019-10-06-finding-errors_files/figure-html/unnamed-chunk-12-1.png" alt="Figure 1. Test accuracies for each combination of mtry, type of $g(\mathbf{x}_i)$, and $\gamma$." width="1344" />
<p class="caption">
Figure 1: Figure 1. Test accuracies for each combination of mtry, type of <span class="math inline">\(g(\mathbf{x}_i)\)</span>, and <span class="math inline">\(\gamma\)</span>.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-13"></span>
<img src="/blog/2019-10-06-finding-errors_files/figure-html/unnamed-chunk-13-1.png" alt="Figure 2. Final number of variables used for each combination of mtry, type of $g(\mathbf{x}_i)$, and $\gamma$" width="1344" />
<p class="caption">
Figure 2: Figure 2. Final number of variables used for each combination of mtry, type of <span class="math inline">\(g(\mathbf{x}_i)\)</span>, and <span class="math inline">\(\gamma\)</span>
</p>
</div>
<p>From the plots above, we can have an idea of what the test
accuracies (Figure 1) and final number of variables used (Figure 2)
is for each combination of <code>mtry</code> (in percentage of variables used),
and type of <span class="math inline">\(g(\mathbf{x}_i)\)</span> (using a mutual information function
or boosted by a standard RF), marginalized over <span class="math inline">\(\lambda_0\)</span>.
Comparing that to
the test accuracy (average of 0.744) and number of variables used (average of 1308) of the standard random forest,
we can see that there has been a good improvement, since most
models have a simelar accuracy to a full random forest, but
are using many fewer features
(from a maximum of around 30 to a minimum of around 5 features).
Regarding the hyperparameter configurations,
it seems that using the normalized importance values
of a standard random forest as <span class="math inline">\(g(\mathbf{x}_i)\)</span> leads to
the best test accuracy results overall, but with more variation across the
different <code>mtry</code> values. As for the number of features used, using
the normalized importance values of a standard random forest
as <span class="math inline">\(g(\mathbf{x}_i)\)</span> results in using just a few variables, also
with a bigger variation across <code>mtry</code> values. The number of features
used for this scenario gets very low, which can be very attractive
if we’re worried about using the least variables as possible.</p>
<p>Now, following what was described before as the ‘full feature
selection procedure’, let’s move on to the next step: selecting the
best penalized models for each training set and reevaluating them.
In the next code chunks, we get the top-3 models for each training id,
arranging first by test accuracy, training accuracy and number of
variables. After that, we create the new model formulas for each model,
rerun the random forest algorithm with each feature set, for each
of the 5 training sets and evaluate their results:</p>
<pre class="r"><code>best_models &lt;- results %&gt;% 
  arrange(desc(accuracy_test), desc(accuracy), n_var) %&gt;% 
  group_by(id) %&gt;% 
  slice(1:3) %&gt;% 
  ungroup() %&gt;% 
  mutate(new_formula = map(model_importance, get_formula))

# Re-evaluating selected variables -----------------
reev &lt;- tibble(forms = best_models$new_formula) %&gt;% 
  tidyr::expand_grid(folds) %&gt;% 
  dplyr::mutate(reev_models = purrr::map2(train, forms, modelling_reev))

results_reev &lt;- reev %&gt;% 
  dplyr::mutate(feat_importance = purrr::map(reev_models, ~{.x$fit$variable.importance}),
                n_var = purrr::map_dbl(feat_importance, n_vars),
                accuracy = 1 - purrr::map_dbl(reev_models, ~{ .x$fit$prediction.error}),
                accuracy_test = purrr::map2_dbl(.x = reev_models, .y = test, ~{ acc_test(.x, test = .y)})) </code></pre>
<table class="table table-condensed table-hover" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
id
</th>
<th style="text-align:right;">
n_var
</th>
<th style="text-align:right;">
accuracy
</th>
<th style="text-align:right;">
accuracy_test
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Fold2
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
0.8638687
</td>
<td style="text-align:right;">
0.971
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold2
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
0.8768484
</td>
<td style="text-align:right;">
0.941
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold2
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
0.8650016
</td>
<td style="text-align:right;">
0.941
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.8607979
</td>
<td style="text-align:right;">
0.941
</td>
</tr>
<tr>
<td style="text-align:left;">
Fold2
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.8566280
</td>
<td style="text-align:right;">
0.941
</td>
</tr>
</tbody>
</table>
<p>The accuracy values are looking very good now, even for the test set.
Note that the <code>results_reev</code> object has 75 rows, since we have run 15
random forests models for each of the 5 training sets. We still need
to reduce this number, so the last step of our methods consists of
gathering the most used features by such models, and creating one
final algorithm. This final model will be evaluated in 20 training and
test sets, so we can be more certain about its accuracy results.
In the following code, we select the top best
30 fitted models (in terms of the accuracies and number of features used)
find the 15 features most used by them, and fit a random forest model
in the 20 new training and test sets using this final 15-features set.</p>
<pre class="r"><code>selected_vars &lt;- results_reev %&gt;% 
  arrange(desc(accuracy_test), desc(accuracy), n_var) %&gt;% 
  slice(1:30) %&gt;% 
  mutate(ind = 1:n(), vars = map(feat_importance, get_vars)) %&gt;% 
  dplyr::select(ind, vars) %&gt;% 
  unnest() %&gt;% 
  group_by(vars) %&gt;% 
  summarise(count = n()) %&gt;% 
  arrange(desc(count))

# Select the final 15 features
final_vars &lt;- selected_vars %&gt;% slice(1:15) %&gt;% pull(vars)
# Create the final formula 
final_form &lt;- paste(&quot;class ~ &quot;, paste0(final_vars, collapse = &#39; + &#39;)) %&gt;%
  as.formula()

# Create the 20 new training and test sets
set.seed(2021)
folds_20 &lt;- rsample::vfold_cv(gravier, v = 20) %&gt;% 
  dplyr::mutate(train =  map(splits, training), test  = map(splits, testing))

# Run the final model for the new train-test sets
final_results &lt;- folds_20$splits %&gt;% map(~{
  train &lt;-  training(.x)
  test &lt;-  testing(.x)
  
  rf &lt;- rand_forest(trees = 500, mtry = 7) %&gt;%
    set_engine(&quot;ranger&quot;, importance = &quot;impurity&quot;) %&gt;% 
    set_mode(&quot;classification&quot;) %&gt;% 
    parsnip::fit(final_form, data = train)
  
  accuracy_test &lt;- acc_test(rf, test = test)
  list(accuracy_test = accuracy_test, 
       accuracy = 1 - rf$fit$prediction.error, 
       imp = rf$fit$variable.importance)
})</code></pre>
<p>The accuracy averages and medians for this final model are shown below.
We can see that the final test accuracy (average) is higher than what
was seen in the previous plots, but now using only 15 features. At
last, we show the variable importance plot for the 15 features used,
arranged by importance order. This plot informs us about which variables
helped the predictions the most, and we can see that the most
important feature really dominates the plot.</p>
<pre class="r"><code>data.frame(accuracy_test = final_results %&gt;% map_dbl(&quot;accuracy_test&quot;), 
           accuracy = final_results %&gt;% map_dbl(&quot;accuracy&quot;)) %&gt;% 
  gather(type, value) %&gt;% 
  group_by(type) %&gt;% 
  summarise(mean = mean(value), median = median(value)) </code></pre>
<table class="table table-condensed table-hover" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
type
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
median
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accuracy
</td>
<td style="text-align:right;">
0.8974934
</td>
<td style="text-align:right;">
0.8971951
</td>
</tr>
<tr>
<td style="text-align:left;">
accuracy_test
</td>
<td style="text-align:right;">
0.8681000
</td>
<td style="text-align:right;">
0.8820000
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-21"></span>
<img src="/blog/2019-10-06-finding-errors_files/figure-html/unnamed-chunk-21-1.png" alt="Figure 3. Average importance values for the final selected variables" width="480" />
<p class="caption">
Figure 3: Figure 3. Average importance values for the final selected variables
</p>
</div>
<div id="how-does-this-compare-to-the-literature" class="section level3">
<h3>How does this compare to the literature?</h3>
<p>This post only intends to quickly demonstrate how the feature selection
via gain penalization can be used, but we can also compare our results
to a few others that have come up in similar literature that used the
same dataset:</p>
<ul>
<li><span class="citation">[@huynh2020improvements]</span> reports a maximum accuracy of 84.52% (page 10)</li>
<li><span class="citation">[@lopez2018double]</span> reports a maximum AUC of 79.7 (page 384)</li>
<li><span class="citation">[@takada2018independently]</span> reports a maximum miscalssification accuracy of ~75% (page 9)</li>
</ul>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
</div>

                        </div>
                        
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="https://brunaw.com/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            <li><a href="https://brunaw.com/categories/debugging">debugging (2)</a>
            </li>
            
        </ul>
    </div>
</div>








<div class="panel sidebar-menu">
    <div class="panel-heading">
      <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            <li><a href="https://brunaw.com/tags/r"><i class="fa fa-tags"></i> r</a>
            </li>
            
        </ul>
    </div>
</div>






                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            <p><p>
                  Hamilton Institute &amp; Department of Statistics<br>
                  Maynooth University, Ireland.
                  </p>
                  <a href='https://www.maynoothuniversity.ie/hamilton'>
                    <img src='http://www.ufpr.br/portalufpr/wp-content/themes/wpufpr_zurb6_portalufpr/images/logo_ufpr_branca.png' width='240px'/>
                  </a></p>


            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

            

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            
        <strong>Hamilton Institute, </strong>
        <br>Maynooth University,
        <br>Maynooth, Ireland.
      </p>
      


          

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2018; all rights reserved.</p>
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?v=3.exp"></script>

<script src="https://brunaw.com/js/hpneo.gmaps.js"></script>
<script src="https://brunaw.com/js/gmaps.init.js"></script>
<script src="https://brunaw.com/js/front.js"></script>


<script src="https://brunaw.com/js/owl.carousel.min.js"></script>


  </body>
</html>
